{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# numpy stack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from autoencoder_BATADAL import load_AEED\n",
    "\n",
    "# os and time utils\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n",
    "class AutoEncoder(object):\n",
    "    \"\"\" Keras-based AutoEncoder (AE) class used for event detection.\n",
    "\n",
    "        Attributes:\n",
    "        params: dictionary with parameters defining the AE structure,\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\" Class constructor, stores parameters and initialize AE Keras model. \"\"\"\n",
    "        \n",
    "        # Default parameters values. If nI is not given, the code will crash later.\n",
    "        params = {\n",
    "            'nI': None,\n",
    "            'nH': 3,\n",
    "            'cf': 1,\n",
    "            'activation' : 'tanh',\n",
    "            'optimizer' : None,\n",
    "            'verbose' : 0\n",
    "            }\n",
    "\n",
    "        for key,item in kwargs.items():\n",
    "            params[key] = item\n",
    "        \n",
    "        self.params = params\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\" Creates Keras AE model.\n",
    "\n",
    "            The model has nI inputs, nH hidden layers in the encoder (and decoder)\n",
    "            and cf compression factor. The compression factor is the ratio between\n",
    "            the number of inputs and the innermost hidden layer which stands between\n",
    "            the encoder and the decoder. The size of the hidden layers between the \n",
    "            input (output) layer and the innermost layer decreases (increase) linearly\n",
    "            according to the cg.\n",
    "        \"\"\"\n",
    "        \n",
    "        # retrieve params\n",
    "        nI = self.params['nI'] # number of inputs\n",
    "        nH = self.params['nH'] # number of hidden layers in encoder (decoder)\n",
    "        cf = self.params['cf'] # compression factor\n",
    "        activation = self.params['activation'] # autoencoder activation function\n",
    "        optimizer = self.params['optimizer'] # Keras optimizer\n",
    "        verbose = self.params['verbose'] # echo on screen\n",
    "        \n",
    "        # get number/size of hidden layers for encoder and decoder\n",
    "        temp = np.linspace(nI,nI/cf,nH + 1).astype(int)\n",
    "        nH_enc = temp[1:]\n",
    "        nH_dec = temp[:-1][::-1]\n",
    "\n",
    "        # input layer placeholder\n",
    "        input_layer = Input(shape=(nI,))\n",
    "\n",
    "        # build encoder\n",
    "        for i, layer_size in enumerate(nH_enc):\n",
    "            if i == 0:\n",
    "                # first hidden layer\n",
    "                encoder = Dense(layer_size, activation=activation)(input_layer)\n",
    "            else:\n",
    "                # other hidden layers\n",
    "                encoder = Dense(layer_size, activation=activation)(encoder)\n",
    "\n",
    "        # build decoder\n",
    "        for i, layer_size in enumerate(nH_dec):\n",
    "            if i == 0:\n",
    "                # first hidden layer\n",
    "                decoder = Dense(layer_size, activation=activation)(encoder)\n",
    "            else:\n",
    "                # other hidden layers\n",
    "                decoder = Dense(layer_size, activation=activation)(decoder)\n",
    "\n",
    "        # create autoencoder\n",
    "        autoencoder = Model(input_layer, decoder)\n",
    "        if optimizer == None:\n",
    "            optimizer = optimizers.Adam(lr = 0.001)\n",
    "\n",
    "        # print autoencoder specs\n",
    "        if verbose > 0:\n",
    "            print('Created autoencoder with structure:');\n",
    "            print(', '.join('layer_{}: {}'.format(v, i) for v, i in enumerate(np.hstack([nI,nH_enc,nH_dec]))))\n",
    "\n",
    "        # compile and return model\n",
    "        autoencoder.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "        autoencoder.summary()\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, x, y, **train_params):\n",
    "        \"\"\" Train autoencoder,\n",
    "\n",
    "            x: inputs (inputs == targets, AE are self-supervised ANN).\n",
    "        \"\"\"        \n",
    "        if self.params['verbose']:\n",
    "            if self.ann == None:\n",
    "                print('Creating model.')\n",
    "                self.create_model()\n",
    "        self.ann.fit(x, y, **train_params)\n",
    "\n",
    "\n",
    "    def predict(self, x, test_params={}):\n",
    "        \"\"\" Yields reconstruction error for all inputs,\n",
    "\n",
    "            x: inputs.\n",
    "        \"\"\"\n",
    "        return self.ann.predict(x, **test_params)\n",
    "\n",
    "class AEED(AutoEncoder):\n",
    "    \"\"\" This class extends the AutoEncoder class to include event detection\n",
    "        functionalities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def difference(x):\n",
    "        return (x[-1] - x[0])**2\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\" Create the underlying Keras model. \"\"\"\n",
    "        self.ann = self.create_model()\n",
    "\n",
    "    def predict(self, x, y, **keras_params):\n",
    "        \"\"\" Predict with autoencoder. \"\"\"        \n",
    "        preds = super(AEED, self).predict(x,keras_params)\n",
    "        errors = pd.DataFrame((y-preds)**2)\n",
    "        return preds, errors        \n",
    "        \n",
    "    def detect(self, x, y, theta, window = 1, average=False, sys_theta = 0, **keras_params):\n",
    "        \"\"\" Detection performed based on (smoothed) reconstruction errors.\n",
    "\n",
    "            x = inputs,\n",
    "            theta = threshold, attack flagged if reconstruction error > threshold,\n",
    "            window = length of the smoothing window (default = 1 timestep, i.e. no smoothing),\n",
    "            average = boolean (default = False), if True the detection is performed\n",
    "                on the average reconstruction error across all outputs,\n",
    "            keras_params = parameters for the Keras-based AE prediction.\n",
    "        \"\"\"\n",
    "        #        preds = super(AEED, self).predict(x,keras_params)\n",
    "        preds, temp = self.predict(x, y, **keras_params)\n",
    "        #temp = (x-preds)**2\n",
    "        if average:\n",
    "            errors = temp.mean(axis=1).rolling(window=window).mean()             \n",
    "            detection = errors > theta\n",
    "        else:\n",
    "            errors = temp.rolling(window=window).mean()\n",
    "            detection = errors.apply(lambda x: x>np.max(theta.name, sys_theta)) \n",
    "            \n",
    "        return detection, errors\n",
    "\n",
    "    def save(self, filename, scaler, theta):\n",
    "        \"\"\" Save AEED modelself.\n",
    "\n",
    "            AEED parameters saved in a .json, while Keras model is stored in .h5 .\n",
    "        \"\"\"\n",
    "        # parameters\n",
    "        with open(filename+'.json', 'w') as fp:\n",
    "            json.dump(self.params, fp)\n",
    "        # keras model\n",
    "        self.ann.save(filename+'.h5')\n",
    "        with open(\"theta\", 'w') as f:\n",
    "            f.write(str(theta))\n",
    "        pickle.dump(scaler, open( \"scaler.p\", \"wb\" ))\n",
    "        # echo\n",
    "        print('Saved AEED parameters to {0}.\\nKeras model saved to {1}'.format(filename+'.json', filename+'.h5'))\n",
    "\n",
    "\n",
    "# functions\n",
    "def load_AEED(params_filename, model_filename):\n",
    "    \"\"\" Load stored AEED. \"\"\"\n",
    "    # load params and create AEED\n",
    "    with open(params_filename) as fd:\n",
    "        params = json.load(fd)\n",
    "    aeed = AEED(**params)\n",
    "\n",
    "    # load keras model\n",
    "    aeed.ann = load_model(model_filename)\n",
    "    return aeed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, window_size = 4):\n",
    "    \"\"\" \n",
    "    Creates the dataset composed by window_size samples of sensor readings and their relative label\n",
    "    \n",
    "    if windows size is 2, it returns a dataset composed [[[x-1, x][x]], [[x, x+1][x+1]], ...]\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset :  list\n",
    "        list of dataset samples\n",
    "    window_size : int\n",
    "        number of samples used for feeding the network.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np array\n",
    "        dataset samples organized in groups of windows_size\n",
    "    np array\n",
    "        target of model prediction\n",
    "    \"\"\"\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset) - window_size - 1):\n",
    "        a = dataset[i:(i + window_size + 1)] #remove +1 to turn into 1-step ahead prediction\n",
    "        data_X.append(a)\n",
    "        data_Y.append(dataset[i + window_size])\n",
    "    return(np.array(data_X), np.array(data_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/WADI/\"\n",
    "df_train_orig = pd.read_csv(data_path+\"train_dataset.csv\",  parse_dates = {'DATETIME': ['Date','Time']} , dayfirst=True)#, parse_dates = ['DATETIME'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = [col for col in df_train_orig.columns if col not in ['Row','Date','Time', 'DATETIME', '2_MV_001_STATUS', '2_LT_001_PV', '2_MV_002_STATUS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale sensor data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df_train_orig[sensor_cols])\n",
    "with open('scaler.p', 'wb') as file:\n",
    "    pickle.dump(scaler,file)\n",
    "# split into training and validation\n",
    "X1, X2, _, _  = train_test_split(X, X, test_size=0.33, random_state=42, shuffle=False)\n",
    "window = 5\n",
    "train_X, train_Y = create_dataset(X1, window) #to use also the current reading\n",
    "test_X, test_Y = create_dataset(X2, window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created autoencoder with structure:\n",
      "layer_0: 82, layer_1: 73, layer_2: 65, layer_3: 57, layer_4: 49, layer_5: 40, layer_6: 32, layer_7: 40, layer_8: 49, layer_9: 57, layer_10: 65, layer_11: 73, layer_12: 82\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 82)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 73)                6059      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 65)                4810      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 57)                3762      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 49)                2842      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 40)                2000      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 40)                1320      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 49)                2009      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 57)                2850      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 65)                3770      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 73)                4818      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 82)                6068      \n",
      "=================================================================\n",
      "Total params: 41,620\n",
      "Trainable params: 41,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model parameters\n",
    "params = {\n",
    "    'nI' : X.shape[1],\n",
    "    'nH' : 6,\n",
    "    'cf' : 2.5,\n",
    "    'activation' : 'tanh',\n",
    "    'verbose' : 1,\n",
    "}\n",
    "\n",
    "# create AutoEncoder for Event Detection (AEED)\n",
    "autoencoder = AEED(**params)\n",
    "autoencoder.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessando/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810432 samples, validate on 399169 samples\n",
      "Epoch 1/500\n",
      " - 336s - loss: 0.0017 - val_loss: 9.2311e-04\n",
      "Epoch 2/500\n",
      " - 205s - loss: 5.2234e-04 - val_loss: 5.8410e-04\n",
      "Epoch 3/500\n",
      " - 198s - loss: 4.1690e-04 - val_loss: 4.7006e-04\n",
      "Epoch 4/500\n",
      " - 227s - loss: 3.4054e-04 - val_loss: 7.0503e-04\n",
      "Epoch 5/500\n",
      " - 329s - loss: 1.8391e-04 - val_loss: 3.0098e-04\n",
      "Epoch 6/500\n",
      " - 287s - loss: 1.6396e-04 - val_loss: 2.6681e-04\n",
      "Epoch 7/500\n",
      " - 275s - loss: 1.1543e-04 - val_loss: 2.2539e-04\n",
      "Epoch 8/500\n",
      " - 263s - loss: 9.3770e-05 - val_loss: 2.0813e-04\n",
      "Epoch 9/500\n",
      " - 313s - loss: 8.3231e-05 - val_loss: 1.9516e-04\n",
      "Epoch 10/500\n",
      " - 227s - loss: 8.0754e-05 - val_loss: 1.8882e-04\n",
      "Epoch 11/500\n",
      " - 272s - loss: 7.4874e-05 - val_loss: 1.8124e-04\n",
      "Epoch 12/500\n",
      " - 216s - loss: 7.0880e-05 - val_loss: 1.8092e-04\n",
      "Epoch 13/500\n",
      " - 243s - loss: 6.7981e-05 - val_loss: 1.8039e-04\n",
      "Epoch 14/500\n",
      " - 251s - loss: 6.6297e-05 - val_loss: 1.7913e-04\n"
     ]
    }
   ],
   "source": [
    "# train models with early stopping and reduction of learning rate on plateau\n",
    "earlyStopping= EarlyStopping(monitor='val_loss', patience=3, verbose=0,  min_delta=1e-5, mode='auto')\n",
    "lr_reduced = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=0, epsilon=1e-4, mode='min')\n",
    "    \n",
    "# initialize time\n",
    "start_time = time.time()\n",
    "\n",
    "# train autoencoder\n",
    "autoencoder.train(X1, X1,\n",
    "            epochs=500,\n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            callbacks = [earlyStopping, lr_reduced],\n",
    "            verbose = 2,\n",
    "            validation_data=(X2, X2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess detection\n",
    "def compute_scores(Y,Yhat):\n",
    "    fpr, recall, _ = roc_curve(Y, Yhat)\n",
    "    return [accuracy_score(Y,Yhat),f1_score(Y,Yhat),precision_score(Y,Yhat),recall[1], fpr[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset with attacks\n",
    "df_test_01 = pd.read_csv(data_path + 'attacks_october_clean_with_label.csv')#, parse_dates = ['DATETIME'], dayfirst=True)\n",
    "print(df_test_01.columns.shape)\n",
    "# scale datasets\n",
    "X3 = pd.DataFrame(index = df_test_01.index, columns = sensor_cols, \n",
    "                  data = scaler.transform(df_test_01[sensor_cols]))\n",
    "#X3, Y3_target = create_dataset(X3.values, window) #to use also the current reading\n",
    "# get targets\n",
    "Y3 = df_test_01['ATT_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#perform detection\n",
    "\n",
    "# get validation reconstruction errors\n",
    "_, validation_errors = autoencoder.predict(X2, X2)\n",
    "# plot distribution of average validation reconstruction errors \n",
    "f, ax = plt.subplots(1, figsize = (8,4))\n",
    "sns.boxplot(validation_errors.mean(axis=1), ax=ax)\n",
    "ax.set_xlim([0,0.005])\n",
    "ax.set_title('Boxplot of average validation reconstruction errors')\n",
    "\n",
    "# set treshold as quantile of average reconstruction error\n",
    "theta = validation_errors.mean(axis = 1).quantile(0.995)\n",
    "with open('theta', 'w') as file:\n",
    "    file.write(str(theta))\n",
    "Yhat3, _ = autoencoder.detect(X3, X3, theta = theta , window = 60, average=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "                 accuracy  f1_score precision    recall        fpr\n",
      "test dataset 01  0.965318  0.655278   0.76973  0.570456  0.0104658\n",
      "train dataset         NaN       NaN       NaN       NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(index = ['test dataset 01', 'train dataset'], \n",
    "                       columns = ['accuracy','f1_score','precision','recall','fpr'])\n",
    "results.loc['test dataset 01'] = compute_scores(Y3,Yhat3) \n",
    "\n",
    "print('Results:\\n')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y3,Yhat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot figure\n",
    "shade_of_gray = '0.75'\n",
    "f, axes = plt.subplots(2,figsize = (40,32))\n",
    "axes[0].plot(Yhat3, color = shade_of_gray, label = 'predicted state')\n",
    "axes[0].fill_between(Yhat3.index, Yhat3.values, where=Yhat3.values <=1, interpolate=True, color=shade_of_gray)\n",
    "axes[0].plot(Y3, color = 'r', alpha = 0.85, lw = 1, label = 'real state')\n",
    "axes[0].set_title('Detection trajectory on test dataset 01 original autoencoder', fontsize = 14)\n",
    "axes[0].set_yticks([0,1])\n",
    "axes[0].set_yticklabels(['NO ATTACK','ATTACK'])\n",
    "axes[0].legend(fontsize = 12, loc = 2)\n",
    "axes[1].plot(Yhat4, color = shade_of_gray, label = 'predicted state')\n",
    "axes[1].fill_between(Yhat4.index, Yhat4.values, where=Yhat4.values <=1, interpolate=True, color=shade_of_gray)\n",
    "axes[1].plot(Y4, color = 'r', alpha = 0.85, lw = 1, label = 'real state')\n",
    "axes[1].set_title('Detection trajectory on test dataset 01 original autoencoder', fontsize = 14)\n",
    "axes[1].set_yticks([0,1])\n",
    "axes[1].set_yticklabels(['NO ATTACK','ATTACK'])\n",
    "axes[1].legend(fontsize = 12, loc = 2)\n",
    "\n",
    "#plt.savefig('original-substitute-detection.png', format='png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
